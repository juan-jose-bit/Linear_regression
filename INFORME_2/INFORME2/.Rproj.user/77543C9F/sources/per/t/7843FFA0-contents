---
title: "Regresión lineal multiple y multicolinealidad"
author: "Juan Jose Rivera Londoño"
date: "29/8/2021"
output: html_document
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(leaps)
library(readxl)
library(plotly)
library(ggplot2)
library(plyr)
library(MASS)
library(car)
library(corrplot)
library(klaR)
library(mctest)
source("D:/SEMESTRE_1_2021/ESTADISTICA_2/Functions.R")
```

### Basede datos.

A continuación se leerá la base de datos sobre la eficacia en el control de infecciones hospitalarias.
```{r cars}
data = read.table("D:/SEMESTRE_1_2021/ESTADISTICA_2/INFORME_2/datos2.txt", header = TRUE, sep = " ", dec = ".")
```

### 1. Estime un modelo de regresión lineal múltiple que explique el Riesgo de Infección en términos de todas las variables predictoras. Analice la significancia de la regresión y de los parámetros individuales. Interprete los parámetros estimados. Calcule e interprete el coeficiente de determinación múltiple R2. Comente los resultados.

A continuación se estimará un modelo con todas las variables predictoras.

```{r pressure, echo=FALSE}
mod1 = lm(Y~.,data=data)
summary(mod1)
```
La prueba F para la regresión nos da un p-value igual a $1.05 \times 10^-6$, con un nivel de significancia del 5% podemos decir que el modelo obtenido con la combinación de estas variables predictoras es significativo, esto no significa que todas las variables sean significativas, de hecho, solo las variables x1 (Duración de la estadía) y x3 (Número de camas) lo son, los demás coeficientes de regresión pueden ser cero dependiendo de una muestra diferente, lo cual implica que estadísticamente estas variables no sean significativas y no aporten información predictiva para Y (Riesgo de infección). Interpretaremos los coeficientes $\beta_1$ y $\beta_3$, el primero significa que en promedio el riesgo de infección incrementa en un 21% por un aumento en un día de estadía cuando las demás variables explicativas permanecen constantes, y el segundo coeficiente representa que el riesgo de infección aumenta en un 4% en promedio por un aumento de 1 cama en el hospital, también con las demás variables constantes. El coeficiente $R^2$ del modelo es de $0.44$ esto significa que un 44% de la variabilidad total en la variable riesgo de infección es explicada por el modelo de regresión. A mi parecer la selección de variables predictoras no aporta mucha información para predecir el riesgo de infección.

### 2. Use la tabla de todas las regresiones posibles, para probar la significancia simultánea del subconjunto de tres variables con los valores p mayores del punto anterior. Según el resultado de la prueba es posible descartar del modelo las variables del subconjunto?.

El subconjunto de variables que tienen los mayores p-values son X2, X4, X5 con p-values iguales a 0.47, 0.15, 0.22 respectivamente. las hipótesis para este tipo de prueba es:

\[H_o: \beta_2=\beta4=\beta_5=0\]
\[H_1: \text{alguno entre } \beta_2,\beta4,\beta_5 \neq 0\]

Para formular esta prueba de hipótesis se requieren 2 modelos, el primero es el modelo de regresión lineal con todas las variables predictoras y el segundo es el modelo reducido, en el cual se eliminan del modelo el subconjunto de variables de la hipótesis nula. El estadístico de prueba será entonces:

\[F=\frac{[SSE(X1,X3)-SEE(X1,X2,X3,X4,X5)]/[(n-3)-(n-6)]}{MSE(X1,X2,X3,X4,X5)}\]

O equivalentemente:

\[F=\frac{[SSR(X1 ,X2, X3, X4, X5)-SSR(X1,X3)]/3}{MSE(X1,X2,X3,X4,X5)}\]

Usando el código desarrollado por el profesor para obtener la tabla de todas las regresiones posibles, tenemos que el SSE del modelo completo es $63.203$ y que el SSE para el modelo reducido es $67.257$, también tenemos que el MSE del modelo completo es $63.203/(n-6)$, donde $n=65$, También se planteara un procedimiento alternativo pero equivalente sin usar la tabla de todas las regresiones posibles y calculando el SSR en vez del SSE, tenemos usando el SSE:

\[F=\frac{[67.257-63.203]/[(65-3)-(65-6)]}{63.203/(65-6)}=1.2614\]

Usando el código equivalente o el SSR encontramos que el F0 es el mismo.

```{r}
mod2 = lm(Y~X1+X3,data=data)

myAllRegTable(mod1,MSE = FALSE)
n=dim(data)[1]
dfn=6-3 
dfd=n-6
f0=((67.257-63.203)/((65-3)-(65-6)))/(63.203/(65-6))
SRR1 = sum((fitted.values(mod1)-mean(data$Y))**2)
SRR2 = sum((fitted.values(mod2)-mean(data$Y))**2)
SSE1 = sum((fitted.values(mod1)-data$Y)**2)
MSE1 = SSE1/(n-6)
F0 = ((SRR1-SRR2)/3)/(MSE1)
## Cuantil de la distribucion f
qf(1-0.05,dfn,dfd)
## Estadistico de prueba con SSE
f0
## Estadistico de prueba con SSR
F0
```
Usando un nivel de significancia del 5%, Como el valor critico o cuantil $F_{\alpha,3,59}=2.76$ tenemos:

 \[F_0<F_{\alpha,3,59}\ ; \ 1.26<2.76 \]
 
 Por lo tanto no podemos rechazar la hipótesis nula y el subconjunto de variables X2, X4, X5 no son estadisticamente significativas, por lo tanto si es posible descartarlas del modelo.

### 3. Plantee una pregunta donde su solución implique el uso exclusivo de una prueba de hipótesis lineal general de la forma $H_0 : L{\times} \beta = 0$ (solo se puede usar este procedimiento y no SSextra), donde especifique claramente la matriz L, el modelo reducido y la expresión para el estadístico de prueba.

Evaluaremos simultáneamente las hipótesis:
\[\beta_2 = \beta_4\]
\[\beta_1 = \beta_3\]
estas pueden ser reescritas como:
\[\beta_2 - \beta_4 = 0\]
\[\beta_1 - \beta_3 = 0\]
O en forma matricial si consideramos todos los parámetros del modelo:
\[
\left[\begin{array}{cc}
0 & 0 & 1 & 0 & -1 & 0\\
0 & 1 & 0 & -1 & 0 & 0
\end{array}\right]
\times
\left[\begin{array}{cc}
\beta_0\\
\beta_1\\
\beta_2\\
\beta_3\\
\beta_4\\
\beta_5
\end{array}\right]
=
\left[\begin{array}{cc}
0\\
0
\end{array}\right]\]
Donde la matriz L es igual a:
\[
L = \left[\begin{array}{cc}
0 & 0 & 1 & 0 & -1 & 0\\
0 & 1 & 0 & -1 & 0 & 0
\end{array}\right]
\]
Para probar la hipótesis dada anteriormente se plantean 2 modelos, uno en el cual la hipótesis nula se cumple, o modelo reducido y el otro es el modelo completo, para el modelo reducido tenemos:
\[
Y = \beta_0+\beta_1X_{1,3}+\beta_2X_{2,4}+\beta_5X_5
\]
Donde:
\[
X_{1,3}=X_1+X_3 \qquad \text{y} \qquad X_{2,4}=X_2+X_4
\]

Ahora teniendo los 2 modelos de regresión el estadístico de prueba es el siguiente:

\[
F_0 = \frac{SSR(X1,X2, X3, X4, X5)-SSR(X13, X24, X5)/(5-3)}{MSE(X1, X2, X3, X4, X5)}
\]
Donde los grados de libertad del numerador son $5-3=2$ y los grados de libertad del denominador son $n-6=59$.
```{r}
y=data$Y
x13 =data$X1+data$X3
x24 =data$X2+data$X4
x5=data$X5
dfnl=2
dfdl=n-6
mod3 = lm(y~x13+x24+x5)
SRR3 = sum((fitted.values(mod3)-mean(data$Y))**2)
F0l = ((SRR1-SRR3)/dfnl)/(MSE1)
qf2 = qf(1-0.05,df1 = dfnl,df2=dfdl)
## Estadístico de prueba
F0l
##Valor crítico de la distribucion F
qf2

```
El estadístico de prueba para la hipótesis planteada es $F_0 = 2.34$, Con un nivel de significáncia del 5% el valor critico de prueba de la distribución F es $F_{\alpha,2,59} = 3.15$ por lo tanto.

\[F_0<F_{\alpha,2,59} \qquad ; \qquad 2.34<3.15\]

Por lo tanto no podemos rechazar la hipótesis nula.

### 4. Realice una validación de los supuestos en los errores y examine si hay valores atípicos, de balanceo e influenciales. Qué puede decir acerca de la validez de éste modelo?. Argumente.

Para validar los supuestos de los errores tenemos que revisar que los residuales:

* Tengan varianza constante
* Se distribuyan aproximadamente normal
* Sean independientes 
* Tengan media cero

Pero ahora lo haremos con los residuales estudentizados ya que deberíamos escalarlos para poder determinar verdaderamente cuando un residual es "grande".

#### Varianza constante
Este supuesto se puede validar con un gráfico de residuales estudentizados del modelo vs valores ajustados de la variable respuesta.

```{r}

res_vs_fit = as.data.frame(cbind(fitted.values(mod1),studres(mod1)))
plt1 = ggplot(data=res_vs_fit,aes(V1,V2)) +
  geom_point()+theme_bw()+
  labs(x="Valores ajustados",y = "Residuales estudentizados")
  
ggplotly(plt1)
```
Como podemos ver en la gráfica la distribución de los residuales es homogénea en todo el espacio, hay una aglomeración de puntos en la parte izquierda del gráfico pero esto es por la cantidad de predicciones que caen en ese rango mas no porque los residuales varían conforme aumenta o disminuyan los valores ajustados, podemos decir que la varianza es constante.

#### Distribución normal en los errores.
Para validar este supuesto podemos realizar y analizar el gráfico de probabilidad normal de los residuales.

```{r}
qqnorm(studres(mod1), 
       ylab="Studentized Residuals", 
       xlab="Normal Scores", 
       main="Normality test") 
qqline(studres(mod1))

shapiro.test(studres(mod1))
```
Como podemos observar en el gráfico los puntos mas alejados del centro de la gráfica (en especial los puntos a la izquierda) se alejan de la recta de normalidad, cabe destacar que no son muchos los puntos que se alejan de esta recta y ademas la prueba de Shapiro-Wilk nos da un p-value igual a 0.7, por esta razón concluimos que los errores si siguen una distribución normal. Aunque concluimos que los residuales si distribuyen normal los puntos a la izquierda del gráfico pueden corregirse a menudo con una transformación de los valores de Y , esto logra estabilizar la varianza y una mayor aproximación a la normalidad. 

#### Independencia y media cero.
Como no tenemos un registro temporal o una secuencia en la cual fueron tomados los datos no podemos concluir nada acerca de la independencia de los errores o no tiene sentido en este caso concluir acerca de este hecho.

Por la manera de conformar el modelo lineal, ya sea por mínimos cuadrados o por máxima verosimilitud (son equivalentes en la determinación de los coeficientes y en esta propiedad en especifico), los residuales del modelo siempre tienen media cero.

#### Observaciones atipicas
Para analizar si en el modelo se encuentran observaciones atípicas, se observan los residuales estudentizados del modelo, estos se calculan como:

```{r}
res_stud = studres(mod1)
res_stan = rstandard(mod1)
res_stud[abs(res_stud)>3]
res_stan[abs(res_stan)>3]
```
Como podemos ver del código anterior, no hay ninguna observación para las cuales se observen que $|ri|$ o $|di|$ sea mayor a 3, en este caso no tenemos observaciones atípicas.

#### Puntos de balanceo.
Los puntos de balanceo son detectados mediante el análisis de los elementos de la diagonal principal de la matriz $H$, los $hii$, se decide si una observación es un punto de balanceo si $hii>\frac{2p}{n}$, donde p es el numero de parámetros del modelo y $\bar{hii}=p/n$ es la media de los $hii$, si $2p=n > 1$ este criterio no funciona pues los hii siempre son menores a 1.

```{r}

x0 = rep(1,dim(data)[1])

X = matrix(c(x0,as.matrix(data[,2:6])),ncol=6)
colnames(X) = c('x0','x1','x2','x3','x4','x5')
betas = solve(t(X) %*% X)%*%(t(X)%*%as.matrix(data$Y))
H = X%*%solve(t(X)%*%X)%*%t(X)

Hii = as.matrix(diag(H))
Hb = dim(betas)[1]/n

## Media de hii
Hb
## valores atipicos
atip = as.matrix(Hii[abs(Hii)>2*Hb])
row.names(atip) = which(Hii>=2*Hb)
atip
```
como podemos ver $\bar{hii}=0.09$, por lo que esta prueba es valida y también podemos ver que las observaciones 22, 23, 27, 30, 45 y 52 son mayores a $2\times Hb = 0.18$ por lo tanto son puntos de balanceo.

#### Puntos influyentes.

Para probar si una observación es un punto influyente utilizamos distintas medidas una es la distancia de Cook y la otra es la distancia DFFITS.el punto sera influyente si la distancia de Cook $Di>1$ o si la distancia $|DFFITS_i|>2 \sqrt{\frac{p}{n}}$.
```{r}
p = dim(betas)[1]
cd = cooks.distance(mod1)
DFFI = dffits(mod1)

### Puntos influyentes
cd[cd>1]
DFFI[abs(DFFI)>2*sqrt(p/n)]
### DFBETAS para cada variable

```

Como podemos ver bajo el criterio de la distancia de Cook no se detecto ningún punto influyente pero bajo el criterio de la distancia DFFITS se detectó que los puntos 30, 41, 45 y 52 son puntos influyentes.

Concluimos finalmente que el modelo si tiene validez en cuanto a los supuestos de los errores ya que estos se cumplen, aun así hay varios puntos que son atípicos e influenciales en el modelo, el $R^2$ del modelo es bajo a mi parecer, los puntos de balanceo tienen una influencia directa en esta estadística de desempeño del modelo, un chequeo de estos puntos es importante ya que nos indican puntos que pueden ser eliminados del modelo llegado el caso de que sean errados (errores de medición etc), los puntos de balanceo "halan" y modifican la regresión en su dirección, se sugiere que se chequeen estos puntos para saber si verdaderamente representan la realidad o si hay errores errores de medición en los datos.

### 5. Verificar la presencia de multicolinealidad usando graficos y/o indicadores apropiados.

Se verificará la presencia de multicolinealidad por medio de un gráfico de la matriz de correlación entre las diferentes variables predictoras y haciendo uso de indicadores como los factores de inflación de la varianza, indices de condición y proporciones de descomposición de varianza.

##### Gráfico de correlación.

```{r}
corr_mat = cor(data[,2:6])
corrplot(corr_mat, type="upper", order="hclust", tl.col="black", tl.srt=45)
pairs(data,lower.panel =myPanel.cor,upper.panel = panel.smooth,diag.panel=myPanel.box,
      labels=names(data))
```

Como se observa en la anterior gráfica, la correlación entre variables predictoras no es muy fuerte, el valor critico para determinar indicios de correlación entre las predictoras es de 0.5 en valor absoluto, como podemos ver el valor máximo es entre las variables es de 0.38 entre x1 y x4, por lo tanto esta prueba no nos da indicios de correlación, y además no es concluyente.

#### Factor de inflación de varianza.
Utilizaremos la función VIF() para calcular la inflación de la varianza, si el VIF es mayor a 5 no tenemos problemas de multicolinealidad.
```{r}
##Según Vif no se encuentran efectos de multicolinealidad
vf = vif(mod1)
vf
## 
```
Como podemos ver el valor para cada variable es menor a 5 por lo que no detectamos problemas de multicolinealidad con esta prueba.

#### Indice de condición y proporciones de varianza.
Calcularemos los indices de condición, si el indice de condición es menor a 10, no tenemos multicolinealidad, si el indice de condición esta entre 10 y 31.62 tenemos multicolinealidad moderada, tenemos un indice de condición mayor a 31.2 tenemos multicolinealidad severa, también analizaremos las proporciones de la varianza $\pi_{i,j}$ si este valor es mayor a 0.5 para 2 o mas variables asociadas a un mismo valor propio podemos decir que existen problemas de multicolinealidad entre las respectivas variables.

```{r}
x1_stan = (data$X1-mean(data$X1))/sqrt(sum((data$X1-mean(data$X1))^2)/(n-1))
x2_stan = (data$X2-mean(data$X2))/sqrt(sum((data$X2-mean(data$X2))^2)/(n-1))
x3_stan = (data$X3-mean(data$X3))/sqrt(sum((data$X3-mean(data$X3))^2)/(n-1))
x4_stan = (data$X4-mean(data$X4))/sqrt(sum((data$X4-mean(data$X4))^2)/(n-1))
x5_stan = (data$X5-mean(data$X5))/sqrt(sum((data$X5-mean(data$X5))^2)/(n-1))
Y_stan = (data$Y-mean(data$Y))/sqrt(sum((data$Y-mean(data$Y))^2)/(n-1))
std_mod = lm(Y_stan~x1_stan+x2_stan+x3_stan+x4_stan+x5_stan)
summary(std_mod)
eigprop(mod1, na.rm = TRUE, Inter = TRUE, prop = 0.5)
eigprop(std_mod, na.rm = TRUE, Inter = TRUE, prop = 0.5)

qnorm(p=1-0.025)
```
Según los indices de condición calculados, tenemos 2 problemas de multicolinealidad moderada y uno de alta multicolinealidad. Analizando los indices de descomposición de la varianza del modelo sin estandarizar no podemos determinar que variables tienen los problemas de multicolinealidad, pero si miramos la descomposición del modelo estandarizado podemos que las variables X3 Y X4 presentan presentan un problema de multicolinealidad moderado esto se puede ver en el valor propio numero 5 ya que el indice de condición de este valor propio en el modelo sin estandarizar es igual a 16.12, se debería analizar si eliminar una de las variables para eliminar los problemas asociados.

